# -*- coding: utf-8 -*-
"""AI final project 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJf9kP2f8e9PYa3yx7B2Ijw1KbayH442
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import RFE
from sklearn.model_selection import KFold
plt.style.use('ggplot')

# We use stock dataset from PTT
ptt=pd.read_csv('/content/drive/MyDrive/PTT.BK.csv')
ptt.head()

ptt.tail()

print(f"We have {len(ptt.index)} datas.")

reg = np.polyfit(ptt['Open'],ptt['Close'],deg=1)
tend = np.polyval(reg,ptt['Open'])
plt.scatter(x=ptt['Open'],y=ptt['Close'],color='Blue')
plt.plot(ptt['Open'], tend, 'r');

# Drop the columns that we don't use
ptt.drop(['Date'], axis = 1, inplace = True)
ptt.drop(['Adj Close'], axis = 1, inplace = True)
ptt.drop(['Volume'], axis = 1, inplace = True)
ptt.head()

# Define x and y
# y is what column do we want to predict
# x is the other columns except the one we want to predict
x=ptt.drop(['Close'], axis=1)
y=ptt['Close']
print(f"x---------------------------{len(x)}\n{x.head()}")
print(f"y---------------------------{len(y)}\n{y.head()}")

# Define x_test, x_train, y_test and y_train data
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100)
print(f"x_test---------------------------{len(x_test)}\n{x_test.head()}")
print(f"x_train---------------------------{len(x_train)}\n{x_train.head()}")
print(f"y_test---------------------------{len(y_test)}\n{y_test.head()}")
print(f"y_train---------------------------{len(y_train)}\n{y_train.head()}")

# Define test and train data
test = pd.concat([x_test, y_test], axis = 1)
train = pd.concat([x_train, y_train], axis = 1)
print(f"test---------------------------{len(test)}\n{test.head()}")
print(f"train---------------------------{len(train)}\n{train.head()}")

# Create model for linear regression and train the model
model = LinearRegression()
model.fit(x_train.values,y_train.values) # training the model
rfe=RFE(model,n_features_to_select=6)
rfe = rfe.fit(x_train.values, y_train.values)

# Predict the test data
pred = rfe.predict(x_test.values)
pred

# Compare the actual test value and the predicted value
pred_concat = pd.concat([y_test.reset_index(),pd.Series(pred, name = "Predicted")],axis=1)
pred_concat.head()

# Sort the index
concat_sorted = pred_concat.sort_values(["index"], ascending=True)
print(concat_sorted)

# Plot the graph to compare the actual and predicted values
plt.plot(concat_sorted['index'],concat_sorted['Close'],color='Blue',label='Close')
plt.plot(concat_sorted['index'],concat_sorted['Predicted'],color='Red',label='Predicted')
plt.legend(loc='lower left')
plt.plot();

# Convert y_test to array
y_test_array = y_test.to_numpy()

y_test_array[1]-pred[1]

# Mean Squared Error estimation
i=0
MSE=0
for i in range(len(y_test)):
  MSE = MSE+((pred[i]-y_test_array[i])**2)
MSE = MSE/len(y_test)
print("MSE:",MSE)

# Root Mean Squared Error estimation
RMSE = math.sqrt(MSE)
print("RMSE:",RMSE)

# Mean Absolute Error estimation
i=0
MAE = 0
for i in range(len(y_test)):
  MAE = MAE+(abs(pred[i]-y_test_array[i]))
MAE = MAE/len(y_test)
print("MAE:",MAE)

# r2 score
r2_score(y_test,pred)

# Create a cross-validation scheme
folds = KFold(n_splits = 5, shuffle = True, random_state = 100)

# Specify range of hyperparameters to tune
hyper_params = [{'n_features_to_select': list(range(1, 4))}]

# Call GridSearchCV()
model_cv = GridSearchCV(estimator = rfe, 
                        param_grid = hyper_params, 
                        scoring= 'r2', 
                        cv = folds, 
                        verbose = 1,
                        return_train_score=True)      

# Fit the model
model_cv.fit(x_train, y_train)

cv_results = pd.DataFrame(model_cv.cv_results_)
cv_results

# Plotting cv results
plt.figure(figsize=(16,6))

plt.ylim([0,1])
plt.plot(cv_results["param_n_features_to_select"], cv_results["mean_test_score"])
plt.plot(cv_results["param_n_features_to_select"], cv_results["mean_train_score"])
plt.xlabel('number of features')
plt.ylabel('r-squared')
plt.title("Optimal Number of Features")
plt.legend(['test score', 'train score'], loc='upper left')
plt.show()

op=input('Enter the opening price: ')
print(f'Opening price is {op}.\n')
hi=input('Enter the high price: ')
print(f'High price is {hi}.\n')
lo=input('Enter the low price: ')
print(f'Low price is {lo}.\n')
clo=rfe.predict(np.array([[op,hi,lo]],dtype=float))
print(f'Predicted closing price is {clo[0]}.')