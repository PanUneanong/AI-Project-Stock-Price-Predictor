# -*- coding: utf-8 -*-
"""AI final project 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SF5GV9fAymCRVOzsFL-nwe6hOHJ5D7Uu
"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn import datasets, tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import math
import seaborn as sns
import pandas as pd
import numpy as np
plt.style.use('ggplot')

# We use stock dataset from PTT
ptt=pd.read_csv('/content/drive/MyDrive/PTT.BK.csv')
ptt.head()

# Drop the columns that we don't use
ptt.drop(['Date'], axis = 1, inplace = True)
ptt.drop(['Adj Close'], axis = 1, inplace = True)
ptt.drop(['Volume'], axis = 1, inplace = True)
ptt.head()

# Define x and y
# y is what column do we want to predict
# x is the other columns except the one we want to predict
x=ptt.drop(['Close'], axis=1)
y=ptt['Close']
print(f"x---------------------------{len(x)}\n{x.head()}")
print(f"y---------------------------{len(y)}\n{y.head()}")

# Define x_test, x_train, y_test and y_train data
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=100)
print(f"x_test---------------------------{len(x_test)}\n{x_test.head()}")
print(f"x_train---------------------------{len(x_train)}\n{x_train.head()}")
print(f"y_test---------------------------{len(y_test)}\n{y_test.head()}")
print(f"y_train---------------------------{len(y_train)}\n{y_train.head()}")

# Random Forest Regressor
rfg = RandomForestRegressor(n_estimators=10,random_state=10)
rfg.fit(x_train.values,y_train.values)
pred = rfg.predict(x_test.values)

pred_concat = pd.concat([y_test.reset_index(),pd.Series(pred, name = "Predicted")],axis=1)
pred_concat.head()

# Sort the index
concat_sorted = pred_concat.sort_values(["index"], ascending=True)
print(concat_sorted)

# Plot decision trees
for i in range(len(rfg.estimators_)):
  tree.plot_tree(rfg.estimators_[i],filled=True)
  plt.show()

# Show only the first decision tree
plt.figure(figsize=(100,40))
tree.plot_tree(rfg.estimators_[0],filled=True)
plt.show()

# Plot the graph to compare the actual and predicted values
plt.plot(concat_sorted['index'],concat_sorted['Close'],color='Blue',label='Close')
plt.plot(concat_sorted['index'],concat_sorted['Predicted'],color='Red',label='Predicted')
plt.legend()
plt.plot();

y_test_array = y_test.to_numpy()
y_test_array[1]-pred[1]

# Mean Squared Error estimation
i=0
MSE=0
for i in range(len(y_test)):
  MSE = MSE+((pred[i]-y_test_array[i])**2)
MSE = MSE/len(y_test)
print("MSE:",MSE)

# Root Mean Squared Error estimation
RMSE = math.sqrt(MSE)
print("RMSE:",RMSE)

# Mean Absolute Error estimation
i=0
MAE = 0
for i in range(len(y_test)):
  MAE = MAE+(abs(pred[i]-y_test_array[i]))
MAE = MAE/len(y_test)
print("MAE:",MAE)

rfg.score(x_test.values, y_test.values)

op=input('Enter the opening price: ')
print(f'Opening price is {op}.\n')
hi=input('Enter the high price: ')
print(f'High price is {hi}.\n')
lo=input('Enter the low price: ')
print(f'Low price is {lo}.\n')
clo=rfg.predict(np.array([[op,hi,lo]],dtype=float))
print(f'Predicted closing price is {clo[0]}.')